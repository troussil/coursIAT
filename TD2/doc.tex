\documentclass[a4paper,francais]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}

\usepackage{subfig}
\usepackage{graphicx}
\graphicspath{{fig/}}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{cancel}

\usepackage{hyperref}

\usepackage{cprotect} %verbatim in footnote

\newcommand{\cad}{c.-à-d.}
\newcommand{\Z}{{\ensuremath\mathbb{Z}}}
\newcommand{\N}{{\ensuremath\mathbb{N}}}
\newcommand{\R}{{\ensuremath\mathbb{R}}}
\newtheorem{Theorem}{Theorem}

%-------- enable or disable correction -----------------------------
\theoremstyle{definition}
\newtheorem{exercice}{Exercice}[section]
\newtheorem*{solution}{Solution}

\usepackage{comment}
%\excludecomment{solution}% commenter/décommenter pour afficher/effacer l'impression des solutions


\title{Optimisation linéaire}
\author{Tristan Roussillon}

\begin{document}

\maketitle

Ce TD aborde le problème de l'optimisation linéaire, défini,
pour des fonctions $f$ et $\{g_i\}_{\{1, \dots, m\}}$ linéaires (ou affines),
comme :
\[
\text{(PL)} \left\{
\begin{array}{c}
  \min_x \ f(x) \ \text{telle que :} \\
  g_i(x) \leq 0, \ i \in I = \{1, \dots, m\} \\
  x \in \R^n \\
\end{array}
\right.
\]

(PL) est résolu en pratique par la méthode du \emph{simplexe}
ou celle \emph{des points intérieurs}. La bibliothèque python
\texttt{SciPy}, par exemple, fournit des
\href{https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linprog.html}{solveurs}
basés sur ces deux méthodes.

\section{Condition d'optimalité nécessaires et suffisantes}


\begin{exercice}
  \label{ex:ex}
  Dans (PL), on a $f(x) = -x_1 + x_2 + 1$, $g_1(x) = -x_1 + x_2$, $g_2(x) = -x_2$, 
  et $g_3(x) = x_1 + x_2 - 1$. Donnez une représentation graphique du problème
  et déduisez-en le minimum global.
\end{exercice}

\begin{solution}
Le minimum global est $x^\star = (1,0)$, avec $f(x^\star) = 0$ (Fig.~\ref{fig:exPL}).  
\begin{figure}
  \includegraphics[width=0.5\textwidth]{PL}
  \caption{Représentation graphique du problème de l'exercice~\ref{ex:ex}.
    En bleu, les numéros des contraintes}
  \label{fig:exPL}
\end{figure}
\end{solution}

Comme la fonction objectif et les contraintes sont linéaires, non seulement
l'hypothèse de qualifications des contraintes est vérifiée, mais les conditions
nécessaires d'optimalité de Kuhn et Tucker sont suffisantes : 
il existe $\{\lambda_i \geq 0\}_{i \in I}$ tels que:
\[
(\text{KT})
\left\{
\begin{array}{ll}
  -{\nabla f}(x) = \sum_{i \in I} \lambda_i {\nabla g_i}(x) & \text{(combinaison linéaire)}\\
  \lambda_i g_i(x) = 0, \ \forall i \in I  & \text{(saturation)}\\
\end{array}
\right.
\]

\begin{exercice}
Vérifiez que le minimum global de l'exercice~\ref{ex:ex} satisfait (KT). 
\end{exercice}

\begin{solution}
  D'après la représentation graphique, $g_2$ et $g_3$ sont saturés, donc
  $\lambda_1 = 0$, $g_2(x) = 0$ et $g_3(x) = 0$. Or, pour tout $x$,
  ${\nabla f}^T(x) = (-1,1)$, ${\nabla g_2}^T(x) = (0,-1)$ et ${\nabla g_3}^T(x) = (1,1)$,
  d'où le système linéaire de 4 équations et 4 inconnues : 
\[
\left\{
\begin{array}{ll}
  - x_2 &= 0 \\
  x_1 + x_2 - 1 &= 0 \\
  \lambda_2 \left(\begin{array}{c} 0 \\ -1 \end{array}\right)
  + \lambda_3 \left(\begin{array}{c} 1 \\ 1 \end{array}\right)
  &= \left(\begin{array}{c} -1 \\ 1 \end{array}\right)
\end{array}
\right.
\]
qui donne
\[
\left\{
\begin{array}{l}
  x_2 = 0 \\
  x_1 = 1 \\
  \lambda_3 = 1 \\
  \lambda_2 = 2 
\end{array}
\right.
\]
\end{solution}

\section{Formulation matricielle canonique et standard}

La plupart des solveurs attendent la description du problème sous une forme matricielle particulière.

\begin{tabular}{c|c}
forme canonique & forme standard \\ \hline
\begin{minipage}{.4\textwidth}
  \[
\left\{
\begin{array}{c}
  \min_x \ c^T x \ \text{telle que :} \\
  Ax \leq b \\
  x \geq 0 \\
\end{array}
\right.
\]
\end{minipage}
&
\begin{minipage}{.4\textwidth}
\[
\left\{
\begin{array}{c}
  \min_x \ c^T x \ \text{telle que :} \\
  Ax = b \\
  x \geq 0 \\
\end{array}
\right.
\]
\end{minipage}
\end{tabular}

\begin{exercice}
  Expliquez pourquoi on ne perd pas en généralité en supposant (i)
  que la fonction objectif s'écrit comme un produit scalaire, (ii)
  que $x \geq 0$. 
  Expliquez comment passer de la forme canonique à la forme standard.
\end{exercice}

\begin{solution}
  (i) Si la fonction objectif est affine, on peut ajouter une variable,
  contrainte à être égale à 1. 
  
  (ii) S'il existe une variable $x_k$ pouvant prendre n'importe quelle valeur réelle,
  on pourra remplacer $x_k$ par la différence $x_k - x_k'$ de deux variables
  $x_k$ et $x_k'$ astreintes, elles, à ne prendre que des valeurs non-négatives.

  Enfin, pour passer de la forme canonique à la forme standard, il convient de remplacer
  toute inégalité par une égalité et une inégalité de signe
  en introduisant une variable d'écart. Par exemple $g(x) \leq 0$ est équivalent
  à $g(x) + y = 0$ et $y \geq 0$.
\end{solution}

\begin{exercice}
\'Ecrivez le problème de l'exercice~\ref{ex:ex} dans sa forme standard.
\end{exercice}

\begin{solution}
  \begin{itemize}
  \item Comme je n'ai pas de contrainte de signe sur $x_1$, je le remplace
    par la différence $x_1 - x_3$ de deux variables à valeurs non-négatives.
  \item Pour avoir une fonction objectif linéaire, j'introduis une variable
    $x_4$ astreinte à être égale à $1$.
  \item Pour les contraintes $1$ et $3$, j'introduis deux variables d'écart $x_5$ et $x_6$
    à valeurs non-négatives. 
  \end{itemize}
En résumé, on a 
\[
\left\{
\begin{array}{cl}
  \min_x \ -x_1 + x_2 + x_3 + x_4 \ \text{telle que :} & \\
  x_1, \dots, x_6 \geq 0 & \text{(contrainte 2 et non-négativité)} \\
  x_4 = 1 & \text{(fct. obj. linéaire)} \\
  -x_1 + x_2 + x_3 + x_5  = 0 & \text{(contrainte 1)} \\
  x_1 + x_2 - x_3 + x_6 = 0   & \text{(contrainte 3)} \\
\end{array}
\right.
\]
On a donc la forme standard en définissant
\begin{itemize}
\item $x^T := (x_1, \dots, x_6) \in \R^6$
\item $c^T := (-1, 1, 1, 1, 0, 0)$,
\item $b^T := (1, 0, 0)$
\item $A :=
  \left(
  \begin{array}{cccccc}
    0 & 0 & 0 & 1 & 0 & 0 \\
    -1 & 1 & 1 & 0 & 1 & 0 \\
    1 & 1 & -1 & 0 & 0 & 1 \\
  \end{array}
  \right)$
\end{itemize}
\end{solution}

\begin{exercice}
  Calculer la solution optimale de l'exercice~\ref{ex:ex} à l'aide d'un solveur
  de votre choix. 
\end{exercice}

\begin{solution}
  TODO
\end{solution}


\section{Classification linéaire}

On suppose donnés $l$ points de $\R^n$, $\{u^k\}_{k \in \{1,\dots,l\}}$ divisés en deux sous-ensembles :
un sous-ensemble d'observations positives $S^+ = \{ u^k, k \in K^+ \}$ et un sous-emsemble
d'observations négatives $S^- = \{ u^k, k \in K^- \}$. On veut déterminer une règle de décision linéaire
permettant de discriminer au mieux les observations positives et les observations négatives. Ce problème
peut être vu comme la recherche de $x \in \R^n$ tel que, en projetant les points de $S^+$ et $S^-$ le
long de $x$, c'est-à-dire en regardant la quantité $u^T x$, on ait deux intervalles disjoints aussi
distants que possible l'un de l'autre.

\begin{exercice}
  Pourquoi est-il nécessaire d'introduire une condition de normalisation sur $u$ ?
\end{exercice}

\begin{solution}
  Sinon, le problème d'optimisation n'est pas borné. En effet, l'unité pour la distance entre les deux
  intervalles est la norme du vecteur. Donc, pour toute une direction admissible pour le vecteur $u$,
  on pourra toujours diminuer sa norme, afin d'avoir des intervalles encore plus distants l'un de
  l'autre.  
\end{solution}

\begin{exercice}
  Montrez qu'en imposant l'une des conditions suivantes, on a un problème d'optimisation linéaire :
  \begin{itemize}
  \item $\underset{k \in K^-}{\max} (u^T x^k) = \pm 1$
  \item $\|u\|_\infty = 1$
  \item $\|u\|_1 = 1$
  \end{itemize}
\end{exercice}

\begin{solution}
%p 618
\end{solution}

\begin{exercice}
\`A l'aide de l'un des \href{https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linprog.html}{solveurs}
de \texttt{SciPy}, complétez le code disponible sur Moodle pour résoudre le problème de classification linéaire. 
\end{exercice}

\begin{solution}
TODO
\end{solution}

Notez que l'application des techniques de programmation linéaire à la résolution de ce type de problème
est à la base des méthodes d'apprentissage connues sous le nom de \emph{Support Vector Machines}
\href{https://en.wikipedia.org/wiki/Support-vector_machine}{(SVM)}


\end{document}


