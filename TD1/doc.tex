\documentclass[a4paper,francais]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}

\usepackage{subfig}
\usepackage{graphicx}
\graphicspath{{fig/}}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{cancel}

\usepackage{hyperref}

\usepackage{cprotect} %verbatim in footnote

\usepackage[english,linesnumbered,ruled,vlined]{algorithm2e}

\newcommand{\cad}{c.-à-d.}
\newcommand{\Z}{{\ensuremath\mathbb{Z}}}
\newcommand{\N}{{\ensuremath\mathbb{N}}}
\newcommand{\R}{{\ensuremath\mathbb{R}}}
\newtheorem{Theorem}{Theorem}

%-------- enable or disable correction -----------------------------
\theoremstyle{definition}
\newtheorem{exercice}{Exercice}[section]
\newtheorem*{solution}{Solution}

\usepackage{comment}
%\excludecomment{solution}% commenter/décommenter pour afficher/effacer l'impression des solutions


\title{Optimisation sans contrainte}
\author{Tristan Roussillon}

\begin{document}

\maketitle

Dans ce TD est traité le cas particulier de la minimisation, sans contrainte,
d'une fonction objectif égale à une somme de fonctions. Cette situation est
très courante dans le contexte de l'apprentissage. L'objectif est de s'entraîner
à modéliser des problèmes d'optimisation et de connaître le lien entre apprentissage
et optimisation. 

\section{Prédiction et méthode des moindres carrés}
\label{sec:mc}
%https://images.math.cnrs.fr/De-la-methode-des-moindres-carres-a-la-descente-de-gradient.html?lang=fr

Nous observons deux caractéristiques, $u$ et $v$, sur un certain nombre d'unités
statistiques : $\{(u_i,v_i)\}_{i = 1,\dots, l}$ est la liste de ces observations.
Or, il existe une relation linéaire entre $u$ et $v$ permettant
de prédire $v$ en fonction de $u$ par $\forall i, \ \hat{v}_i := x_1u_i + x_2$.
La méthode des moindres carrés consiste à chercher les paramètres $x_1$ et $x_2$
qui minimisent la somme, sur toutes les unités $i$, des carrés des écarts entre la
prédiction et son observation. 

\begin{exercice}
  \'Ecrire le problème de la régression linéaire par la méthode des moindres carrés
  sous la forme suivante
  \[
  \min_{x \in \R^n} \ f(x), \ \text{telle que} \
  f(x) = \sum_{i = 1}^l q_i(x) 
  \]

  \begin{itemize}
  \item Que représente $x$ ? Que représente et que vaut $n$ ?
  \item Que sont les fonctions $\{q_i\}_{i = \{1,\dots,l\}}$ ?
  \end{itemize}
\end{exercice}

\begin{solution}
  $x(x_1,x_2)$ est le vecteur de paramètres à chercher ; il y a donc $n=2$ inconnues.
  Les fonctions $\{q_i\}_{i = \{1,\dots,l\}}$ représentent, pour chacun des $l$ individus, les carrés des
  écarts entre la prédiction, $\hat{v}_i = x_1u_i + x_2$, et son observation, $v_i$, et valent pour tout $i$,
  $(v_i - (x_1u_i + x_2))^2$.

  D'où
  \[
  \min_{x \in \R^n} \ f(x), \ \text{telle que} \
  f(x) = \sum_{i = 1}^l (v_i - (x_1u_i + x_2))^2 
  \]
\end{solution}

\begin{exercice}
En utilisant le Théorème~\ref{th:fonc-conv}, montrer que $f$ est convexe.   
\end{exercice}

\begin{Theorem}
  \label{th:fonc-conv}
  Une combinaison linéaire à coefficients positifs de fonctions convexes est une fonction convexe.
\end{Theorem}

\begin{solution}
  D'après le Théorème~\ref{th:fonc-conv}, pour montrer que $f$ est convexe, il suffit de montrer que
  pour tout $i$, $q_i$ est convexe.
  Or, pour tout $i$, tout $x$,
  \[
  q_i(x) =  (v_i - (x_1u_i + x_2))^2 = x_1^2 u_i^2 + x_2^2 + 2u_ix_1x_2 - 2v_iu_ix_1 - 2v_ix_2 + v_i^2.
  \]
  On en déduit le hessien
  \[
  \nabla^2q_i(x) = 
  \left(
  \begin{array}{cc}
    2u_i^2 & 2u_i \\
    2u_i & 2 \\
  \end{array}
  \right)
  \]
  dont les valeurs propres sont les solutions de :
  \[
  \det{(\nabla^2q_i(x) - \lambda I)} = 0, 
  \]
  équivalent à
  \[
  \lambda^2 - \lambda\text{Trace}(\nabla^2q_i(x)) + \cancel{\det{(\nabla^2q_i(x))}}
  = \lambda(\lambda - (2 + 2u_i^2)) = 0, 
  \]
  {\cad}, $0$ et $(2 + 2u_i^2)$, tous deux positifs.

  On en conclut que pour tout $i$, $q_i$ est convexe car pour tout $x$,
  $\nabla^2q_i(x)$ est semi-définie positive.  
\end{solution}

\begin{exercice}
   Donner l'optimum global.
\end{exercice}

\begin{solution}
  Comme $f$ est convexe, il suffit de trouver un point $x$ stationnaire,
  {\cad} tel que $\nabla f(x) = 0$.

  Or, pour tout $i$, ${\nabla q_i}^T(x) = \big( 2u_i (u_ix_1 + x_2 - v_i), 2(u_ix_1 + x_2 - v_i) \big)$.

  On en déduit qu'il faut résoudre :
  \[
  \left\{
  \begin{array}{cc}
    \sum_i^l u_i (u_ix_1 + x_2 - v_i) &= 0 \\
    \sum_i^l (u_ix_1 + x_2 - v_i) &= 0
  \end{array}
  \right.
  \]
  Du développement de la seconde équation découle :
  \[
  x_2 = \frac{1}{l} \sum_i^l (v_i - u_ix_1) = \frac{1}{l} \sum_i^l v_i - \frac{1}{l} x_1\sum_i^l u_i. 
  \]
  Notant $\bar{u}$ et $\bar{v}$ respectivement les moyennes $\frac{1}{l} \sum_i^l u_i$ et $\frac{1}{l} \sum_i^l v_i$, on a :
  \[
  x_2 = \bar{v} + x_1 \bar{u}.
  \]
  Remplaçant $x_2$ par sa valeur dans la première equation et développant :
  \[
  \sum_i^l u_i^2 x_1 + \sum_i^l u_i (\bar{v}) - \sum_i^l u_i (x_1\bar{u}) - \sum_i^l u_iv_i = 0,
  \]
  équivalent à 
  \[
  \sum_i^l u_i^2 x_1 + l\bar{u}\bar{v} - x_1 l{\bar{u}}^2  - \sum_i^l u_iv_i = 0.
  \]
  D'où
  \[
  x_1 = \frac{\sum_i^l u_iv_i - l\bar{u}\bar{v}}{\sum_i^l u_i^2 - l{\bar{u}}^2}
  \]
  ou plus simplement :
  \[
  x_1 = \frac{ \text{cov}(u,v) }{ \text{var}(u) } 
  \]
  
\end{solution}

\section{Le perceptron, l'ancêtre des résaux de neurones}

\let\vec\mathbf

Dans cette section, nous nous écartons des notations du cours pour adopter les
notations utilisées habituellement dans le contexte des réseaux de neurones.

Nous observons des grandeurs réelles représentées par un vecteur $\vec{x}$
(par ex. l'âge et la pression sanguine), ainsi qu'un état binaire $y$
(par ex. être atteint d'une maladie ou non), sur un certain nombre d'unités
statistiques : $\{(\vec{x}_i,y_i)\}_{i = 1,\dots, n}$ est l'\emph{ensemble d'apprentissage}.
Or, il existe une règle de décision permettant de prédire $y$ en fonction de $\vec{x}$
de la forme suivante :
\[
\forall i, \quad
\hat{y}_i :=
\left\{
\begin{array}{ll}
  +1 & \quad \mathrm{si}\quad \vec{w}\cdot\vec{x}_i + b > 0 \\
  -1 & \quad \mathrm{si}\quad \vec{w}\cdot\vec{x}_i + b < 0 \\
\end{array}
\right.
\]
Le vecteur $\vec{w}$ (de même dimension que $\vec{x}$)
est appelé \emph{poids} et le scalaire $b$, \emph{biais}.

Le perceptron, qui est l'ancêtre des réseaux de neurones, modélise ce type
de problème de classification linéaire et est associé à un algorithme qui
permet de trouver, à partir de l'ensemble d'apprentissage, les paramètres
$\vec{w},b$ inconnus. 

\begin{exercice}
  Pourquoi le perceptron ne fait aucune erreur de classification
  si et seulement si $y_i (\vec{w}\cdot\vec{x}_i + b) > 0$ pour tout $i$ ?
  Pourquoi avec une paire $\vec{w}^\star,b^\star$ qui minimise la fonction 
  \[
  Q(\vec{w},b) := - \sum^n_{i=1} y_i (\vec{w}\cdot\vec{x}_i + b)
  \]
  le perceptron classifie sans erreur les données de l'ensemble d'apprentissage ?
  Quel problème pose ce type d'optimisation ?
\end{exercice}

\begin{solution}
Le perceptron ne fait aucune erreur si et seulement si 
\[
\forall i, \quad
\left\{
\begin{array}{ll}
  y_i = 1 & \quad \mathrm{et}\quad \vec{w}\cdot\vec{x}_i + b > 0 \\
  y_i = -1 & \quad \mathrm{et}\quad \vec{w}\cdot\vec{x}_i + b < 0 \\
\end{array}
\right.
\]
ce qui est équivalent à $- y_i (\vec{w}\cdot\vec{x}_i + b) < 0$ pour tout $i$.
Par conséquent, s'il existe une paire $(\vec{w}^0,b^0)$ pour laquelle
le perceptron ne fait aucune erreur, alors pour tout $i$,
$- y_i (\vec{w}^0\cdot\vec{x}_i + b^0) < 0$ et donc $Q(\vec{w}^0,b^0) < 0$.
La paire $(\vec{w}^\star,b^\star)$ qui donne la plus petite valeur de $Q$
fait aussi bien l'affaire car $Q(\vec{w}^\star,b^\star) \leq Q(\vec{w}^0,b^0) < 0$.

S'il existe une paire $(\vec{w}^0,b^0)$ telle que $Q(\vec{w}^0,b^0) < 0$.
Il suffit de multiplier $\vec{w}^0$ et $\vec{b}^0$ par une constante positive
$\lambda > 0$ pour avoir une plus petite valeur de $Q$. La
fonction $Q$ n'est pas bornée inférieurement et sa valeur minimale
est en ce sens mal définie. 
\end{solution}

\begin{exercice}
  Soient $E_{\vec{w},b} := \{i \ | \ y_i (\vec{w}\cdot\vec{x}_i + b) < 0\}$, l'ensemble des erreurs,
  c-à-d. l'ensemble des cas mal classés par le perceptron, 
  et la fonction objectif restreinte à $E_{\vec{w},b}$ suivante :
  \[
  Q'(\vec{w},b) := - \sum_{i \in E_{\vec{w},b}} y_i (\vec{w}\cdot\vec{x}_i + b).
  \]

  Expliquez pourquoi $Q'$ est bornée inférieurement. 
  Calculez le gradient de $Q'$\footnote{Vous devez dériver $Q'$ par rapport aux
    composantes du vecteur $\vec{w}$ et par rapport à $b$.}.
  En utilisant le schéma général de la descente de gradient,
  proposez une règle de mise à jour des paramètres $\vec{w}$ et $b$
  pour trouver la paire qui minimise $Q'$. 
\end{exercice}

\begin{solution}
  Par définition, pour tout $i$ de $E_{\vec{w},b}$,
  $- y_i (\vec{w}\cdot\vec{x}_i + b) > 0$ et $0$ est donc un minorant pour $Q'$. 
  
  Pour tout $i$, la dérivée partielle de $-y_i (\vec{w}\cdot\vec{x}_i + b)$
  par rapport à $\vec{w}$ est $-y_i\vec{x}_i$, tandis que celle par
  rapport à $b$ est $-y_i$, d'où l'on déduit que le gradient
  de $-y_i (\vec{w}\cdot\vec{x}_i + b)$ par rapport à un vecteur
  composé de $\vec{w}$ et $b$ est un vecteur composé de $-y_i\vec{x}_i$
  et $-y_i$. 
  Comme le gradient est un opérateur linéaire, $\nabla Q'$ s'obtient comme
  la somme de ces vecteurs pour tout $i\in E_{\vec{w},b}$.
  
  Pour une constante positive $\lambda > 0$, qu'on appelle dans ce
  contexte \emph{taux d'apprentissage}, la descente de gradient
  s'exprime ainsi:
  \[
  \left(\begin{array}{c}
    \vec{w} \\
    b \\
  \end{array}
  \right)
  \leftarrow
  \left(\begin{array}{c}
    \vec{w} \\
    b \\
  \end{array}
  \right)
  +
  \lambda
  \sum_{i\in E}
  \left(\begin{array}{c}
    y_i\vec{x}_i \\
    y_i \\
  \end{array}
  \right).
  \]  
\end{solution}

\begin{exercice}
  Comme $Q'$ est une somme de fonctions, une alternative à la descente de gradient classique
  consiste à mettre à jour les paramètres $\vec{w}$ et $b$ après chaque paire $(\vec{x}_i, y_i)$
  considérée, c'est ce qu'on appelle le \emph{gradient stochastique}.
  Cette pratique est souvent choisie quand l'ensemble d'apprentissage est grand.
  \'Ecrire l'algorithme d'apprentissage complet mettant en oeuvre cette stratégie. 
\end{exercice}

\begin{solution}
  La règle de mise à jour est maintenant exécutée pour chaque paire $(\vec{x}_i, y_i)$
  qui a été mal classée et s'écrit plus simplement ainsi: 
  \[
  \left(\begin{array}{c}
    \vec{w} \\
    b \\
  \end{array}
  \right)
  \leftarrow
  \left(\begin{array}{c}
    \vec{w} \\
    b \\
  \end{array}
  \right)
  +
  \lambda
  \left(\begin{array}{c}
    y_i\vec{x}_i \\
    y_i \\
  \end{array}
  \right).
  \]
  D'où l'algorithme:
  \begin{algorithm}[htbp]
    \caption{Algorithme d'apprentissage du perceptron}
    \KwIn{l'ensemble d'apprentissage $\{(\vec{x}_i,y_i)\}_{i = 1,\dots, n}$,\\
      le taux d'apprentissage $\lambda$}
    \KwOut{poids $\vec{w}$ et biais $b$ du perceptron}
    \Repeat{$\forall i, \ y_i(\vec{w}\cdot\vec{x}_i + b) \geq 0$}{
      \ForEach{$i = 1,\dots, n$}{
        \If{$y_i(\vec{w}\cdot\vec{x}_i + b) < 0$}{
          $\vec{w} \leftarrow \vec{w} + \lambda y_i\vec{x}_i$ \;
          $b \leftarrow b + \lambda y_i$ \;
        }
      }
    }(\tcp*[h]{plus d'erreurs})
    \Return{$\vec{w}, b$} \;
  \end{algorithm}
\end{solution}

Le perceptron est un cas particulier de réseau de neurones à une couche
avec une fonction d'activation de type signe. Ce modèle et l'algorithme
d'apprentissage qui lui est associé ont de nombreuses limitations,
notamment l'incapacité de traiter des données non linéairement
séparables. En revanche, il a été montré plus tard que les réseaux de
neurones d'au moins deux couches (avec des fonctions d'activation non
linéaires et comportant suffisamment de neurones), sont capables d'approximer
n'importe quelles fonctions. 

\section{Pour aller plus loin}

Lisez l'article \cite{hinton86}. Il s'agit de l'un des articles pionniers
de l'apprentissage par rétro-propagation dans les réseaux neuronaux. L'un des
co-auteurs, G. Hinton, a reçu le prix Turing 2019 (en même temps de Y. LeCun)
pour ses travaux en intelligence artificielle.  

\begin{exercice}
Qu'est-ce qu'un réseau de neurone ?
\end{exercice}

\begin{solution}
  Un réseau de neurones est un ensemble interconnecté d'unités, organisés en couches.
  La couche inférieure contient les entrées, la couche supérieure les sorties.
  Il peut y avoir des couches d'unités intermédiaires. Les unités sont reliées
  uniquement à des unités d'une couche supérieure. Chaque connection entre deux unités
  a une pondération dont la valeur optimale est cherchée au cours de l'apprentissage. 

  Chaque unité $i$ a une valeur d'entrée et une valeur de sortie. La valeur de sortie, notée $\hat{y}_i$,
  est l'évaluation d'une fonction $f$, en général non-linéaire\footnote{la fonction
    sigmoïde est souvent utilisée : $\frac{1}{1 + \exp^{-y_i}}$},
  de son entrée $y_i$ : $\hat{y}_i = f( y_i )$.
  La valeur d'entrée d'une unité $i$ est calculée comme une combinaison linéaires
  des valeurs de sortie des unités $j$ de la couche inférieure qui lui sont connectées : 
  \begin{equation}
    \label{eq:entree}
    y_i = \sum_j \hat{y}_j w_{ij}. 
  \end{equation}

  Certaines unités, appelées biais, ont une valeur d'entrée fixée à 1.
\end{solution}

\begin{exercice}
Quel est le problème d'optimisation posé ?
Quelle méthode d'optimisation est employée pour le résoudre ?
\end{exercice}

\begin{solution}
  L'objectif de l'apprentissage est de trouver le poids des connections assurant que
  pour chaque vecteur d'entrées, le vecteur de sorties du réseau est suffisamment proche
  de la sortie attendue. Pour un ensemble d'observation entrées-sorties, il s'agit de
  trouver la pondération qui minimise le carré des écarts entre les sorties observées
  pour des entrées données et les sorties prédites par le réseau pour les mêmes entrées
  (cf. équation 3 de \cite{hinton86}).

  La méthode d'optimisation proposée est une méthode itérative de descente de gradient
  (cf. équations 8 et 9 de \cite{hinton86}), le gradient étant lui-même calculé par
  rétro-propagation (cf. équations 4 à 7 de \cite{hinton86}).
\end{solution}

\bibliographystyle{plain}
\bibliography{refs}

\end{document}


